{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão Linear Múltipla com NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os dados aqui utilizados representam as notas de alunos de Computação da UFCG em algumas disciplinas do primeiro período. A última coluna é a variável alvo representando o CRA final depois de concluir o curso. As outras colunas são algumas disciplinas do primeiro período. O pressuposto aqui é que as notas em disciplinas no primeiro período ajudam a explicar o CRA final dos alunos de computação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Versão Vetorizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mse_vectorized(w, X, Y):\n",
    "    res = Y - np.dot(X, w)\n",
    "    totalError = np.dot(res.T, res)\n",
    "    \n",
    "    return totalError / float(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_gradient_vectorized(w_current, X, Y, learningRate):\n",
    "    res = Y - np.dot(X, w_current)\n",
    "    \n",
    "    gradients = -2 * np.dot(X.T, res)\n",
    "    w = w_current - learningRate * gradients\n",
    "    \n",
    "    return [w, gradients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_runner_vectorized(starting_w, X, Y, learning_rate, epsilon):\n",
    "    w = starting_w\n",
    "    grad = np.array([np.inf, np.inf])\n",
    "    \n",
    "    i = 0\n",
    "    while (np.linalg.norm(grad) >= epsilon):\n",
    "        w, gradients = step_gradient_vectorized(w, X, Y, learning_rate)\n",
    "        grad = gradients\n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            print(\"MSE na iteração {0} é de {1}\".format(i, compute_mse_vectorized(w, X, Y)))\n",
    "        i += 1\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    points = np.genfromtxt(\"sample_treino.csv\", delimiter=\",\", skip_header = 1)\n",
    "    points = np.c_[np.ones(len(points)),points]\n",
    "    X = points[:, :-1] # independent variables\n",
    "    Y = points[:, 6][:, np.newaxis] # dependent variables\n",
    "    init_w = np.zeros((6, 1))\n",
    "    learning_rate = 0.0003\n",
    "    epsilon = 0.9\n",
    "    \n",
    "    print(\"Executando...\")\n",
    "    print(\"Gradiente descendente iniciando com erro = {0}\".format(compute_mse_vectorized(init_w, X, Y)))\n",
    "    tic = time.time()\n",
    "    w = gradient_descent_runner_vectorized(init_w, X, Y, learning_rate, epsilon)\n",
    "    toc = time.time()\n",
    "    \n",
    "    print(\"Gradiente descendente convergiu com erro = {0} e:\".format(compute_mse_vectorized(w, X, Y)))\n",
    "    for var in range(0, len(w)):\n",
    "        print(\"w_{0} = {1}\".format(var, w[var]))\n",
    "    \n",
    "    print(\"Versão vetorizada rodou em: \" + str(1000*(toc-tic)) + \" ms\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando...\n",
      "Gradiente descendente iniciando com erro = [[54.47995386]]\n",
      "MSE na iteração 0 é de [[15.39415211]]\n",
      "MSE na iteração 1000 é de [[0.43036269]]\n",
      "MSE na iteração 2000 é de [[0.42891282]]\n",
      "MSE na iteração 3000 é de [[0.42766679]]\n",
      "MSE na iteração 4000 é de [[0.42650933]]\n",
      "MSE na iteração 5000 é de [[0.42543391]]\n",
      "MSE na iteração 6000 é de [[0.42443472]]\n",
      "MSE na iteração 7000 é de [[0.42350635]]\n",
      "MSE na iteração 8000 é de [[0.42264379]]\n",
      "MSE na iteração 9000 é de [[0.42184238]]\n",
      "MSE na iteração 10000 é de [[0.42109776]]\n",
      "MSE na iteração 11000 é de [[0.42040593]]\n",
      "MSE na iteração 12000 é de [[0.41976314]]\n",
      "MSE na iteração 13000 é de [[0.41916591]]\n",
      "MSE na iteração 14000 é de [[0.41861102]]\n",
      "MSE na iteração 15000 é de [[0.41809545]]\n",
      "MSE na iteração 16000 é de [[0.41761644]]\n",
      "MSE na iteração 17000 é de [[0.41717137]]\n",
      "MSE na iteração 18000 é de [[0.41675786]]\n",
      "MSE na iteração 19000 é de [[0.41637365]]\n",
      "MSE na iteração 20000 é de [[0.41601668]]\n",
      "MSE na iteração 21000 é de [[0.41568501]]\n",
      "MSE na iteração 22000 é de [[0.41537685]]\n",
      "Gradiente descendente convergiu com erro = [[0.41509302]] e:\n",
      "w_0 = [1.00514726]\n",
      "w_1 = [0.11616793]\n",
      "w_2 = [0.07996134]\n",
      "w_3 = [0.16242923]\n",
      "w_4 = [0.41837732]\n",
      "w_5 = [0.02929304]\n",
      "Versão vetorizada rodou em: 615.332841873 ms\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando o pacote __scikit learn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipleLinearRegression(X, Y):\n",
    "    # Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    # Train the model using all dataset\n",
    "    regr.fit(X, Y)\n",
    "\n",
    "    return regr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    # Load the dataset\n",
    "    points = np.genfromtxt(\"sample_treino.csv\", delimiter = \",\", skip_header = 1)\n",
    "    X = points[:, :-1] # independent variables\n",
    "    Y = points[:, 5] # dependent variable\n",
    "    \n",
    "    print(\"Executando...\")\n",
    "    tic = time.time()\n",
    "    model = multipleLinearRegression(X, Y)\n",
    "    toc = time.time()\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    print(\"Modelo do sklearn convergiu com erro = {0} e:\".format(mean_squared_error(Y, predictions)))\n",
    "    \n",
    "    # The coefficients\n",
    "    for coef in range(0, len(model.coef_)):\n",
    "        if (coef == 0):\n",
    "            print(\"w_{0} = {1}\".format(coef, model.intercept_))\n",
    "        \n",
    "        print(\"w_{0} = {1}\".format(coef+1, model.coef_[coef]))\n",
    "    \n",
    "    \n",
    "    print(\"Versão com sklearn rodou em: \" + str(1000*(toc-tic)) + \" ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executando...\n",
      "Modelo do sklearn convergiu com erro = 0.411337589228 e:\n",
      "w_0 = 1.73771151379\n",
      "w_1 = 0.103041432463\n",
      "w_2 = 0.0464367008507\n",
      "w_3 = 0.164098344192\n",
      "w_4 = 0.381178426656\n",
      "w_5 = 0.0202781576248\n",
      "Versão com sklearn rodou em: 259.8528862 ms\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram implementadas duas versões do algoritmo de regressão linear múltipla, com o objetivo de encontrar um modelo que mostrasse uma relação entre as notas dos alunos nas disciplinas do primeiro período e o seu CRA final. A primeira versão foi implementada com gradiente descendente e a segunda com os métodos do pacote **sklearn**. O modelo do sklearn executou mais rápido, mas, em ambas as versões, os parâmetros dos modelos ficaram bem parecidos.\n",
    "\n",
    "A partir dos modelos gerados é possível perceber que a variável (disciplina) que mais influencia no CRA final do aluno é Introdução a Computação, enquanto que a que menos influencia, a partir destes dados, é Cálculo II."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
